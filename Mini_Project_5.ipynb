{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNZiNu9BcfBM"
      },
      "outputs": [],
      "source": [
        "### Steps 1, 2, and 4 ### I will import necessary libraries as the steps progress in the code block\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "go_fund_me = pd.read_csv('raw_data.csv', sep = ',', on_bad_lines='skip') # Skips reading the 'bad data' which allows to be assigned to a DataFrame\n",
        "\n",
        "### Target and predictors\n",
        "go_fund_me['raised'] = pd.to_numeric(go_fund_me['raised'], errors='coerce')\n",
        "\n",
        "target = 'raised'\n",
        "predictors = ['category', 'goal', 'country', 'cover_photo','num_photo_main_body' ] ### DO NOT FORGET TO ADD THE PREDICTOR FOR VECTORIZER\n",
        "\n",
        "### To encode the categorical variables\n",
        "categorical_col = ['category', 'country','cover_photo']\n",
        "label_encoders = {}\n",
        "\n",
        "model_data = go_fund_me[predictors + [target]].copy()\n",
        "\n",
        "for col in categorical_col:\n",
        "  le = LabelEncoder()\n",
        "  go_fund_me[col] = le.fit_transform(go_fund_me[col].fillna('Unknown'))\n",
        "  label_encoders[col] = le\n",
        "\n",
        "### If any missing values\n",
        "model_data = model_data.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3\n",
        "##### Correlation Matrix of all the variables within the df\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "### To only select numerical columns\n",
        "numemrical_columns = go_fund_me.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "### Corr matrix\n",
        "corr_m = go_fund_me[numemrical_columns].corr()\n",
        "print(corr_m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs5ZyaqH5eFN",
        "outputId": "0ab86767-219b-4e7d-fa37-fa0cfe88ce7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     category      goal   country  cover_photo  \\\n",
            "category             1.000000  0.004256  0.031509    -0.008339   \n",
            "goal                 0.004256  1.000000  0.001110     0.000155   \n",
            "country              0.031509  0.001110  1.000000    -0.002472   \n",
            "cover_photo         -0.008339  0.000155 -0.002472     1.000000   \n",
            "num_photo_main_body -0.096581 -0.001846 -0.009740     0.004434   \n",
            "raised               0.266786 -0.001641 -0.015571    -0.003117   \n",
            "\n",
            "                     num_photo_main_body    raised  \n",
            "category                       -0.096581  0.266786  \n",
            "goal                           -0.001846 -0.001641  \n",
            "country                        -0.009740 -0.015571  \n",
            "cover_photo                     0.004434 -0.003117  \n",
            "num_photo_main_body             1.000000  0.026297  \n",
            "raised                          0.026297  1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### To add vectorizer description data into predictors list\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=50, stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(go_fund_me['clean_description'].fillna('').astype(str))\n",
        "\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=go_fund_me.index)\n",
        "\n",
        "combined_data = pd.concat([go_fund_me, tfidf_df], axis=1)\n",
        "\n",
        "### We need to add the features with the existing predictors completed in intial steps\n",
        "tfidf_features = tfidf_df.columns.tolist()\n",
        "updated_predictors = predictors + tfidf_features\n",
        "\n",
        "combined_data = combined_data.dropna()\n",
        "\n",
        "### Step 5 Now we split the data into training and testing sets after the predictors have been updated\n",
        "\n",
        "x_combined = combined_data[updated_predictors]\n",
        "y_combined = combined_data[target]\n",
        "x_train_combined, x_test_combined, y_train_combined, y_test_combined = train_test_split(x_combined, y_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "### Step 6 Regression model\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(x_train_combined, y_train_combined)\n",
        "\n",
        "### Step 7 Evaluate the model to test data\n",
        "y_pred_combined = linear_model.predict(x_test_combined)\n",
        "mse = mean_squared_error(y_test_combined, y_pred_combined)\n",
        "r2 = r2_score(y_test_combined, y_pred_combined)\n",
        "\n",
        "mse, r2\n",
        "\n",
        "### Step 8 Result Prediction\n",
        "\n",
        "new_data = pd.DataFrame({\n",
        "    'category': ['Memorial'],\n",
        "    'goal': [7000],\n",
        "    'country': ['US'],\n",
        "    'cover_photo': [True],\n",
        "    'num_photo_main_body': [3],\n",
        "    'clean_description': ['My father has passed.'] ### This can be changed to reflect how much of a difference the amount raised can be\n",
        "})\n",
        "\n",
        "### Need to encode the new categorical data given\n",
        "new_data['cover_photo'] = new_data['cover_photo'].astype(int)\n",
        "for col in ['category', 'country']:\n",
        "  le = label_encoders[col]\n",
        "  new_data[col] = le.transform(new_data[col])\n",
        "\n",
        "### Need to generate the tfidf features for new description\n",
        "tfidf_new = vectorizer.transform(new_data['clean_description']).toarray()\n",
        "tfidf_new_df = pd.DataFrame(tfidf_new, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "### Combine the feature generated with the new data frame\n",
        "new_data_combined = pd.concat([new_data.drop(columns=['clean_description']), tfidf_new_df], axis=1)\n",
        "\n",
        "### To make sure that the new data columns have the same columns as orginal training data\n",
        "new_data_combined = new_data_combined.reindex(columns=x_combined.columns, fill_value=0)\n",
        "\n",
        "predicted_raised = linear_model.predict(new_data_combined)\n",
        "\n",
        "print(f\"Predicted Raised Amount: ${predicted_raised[0]:.2f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_UgWidhlnI0",
        "outputId": "04ea8265-55a5-459c-b6ba-1bde8ea32d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Raised Amount: $8299.68\n"
          ]
        }
      ]
    }
  ]
}